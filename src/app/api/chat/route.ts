import { NextRequest, NextResponse } from 'next/server';
import { getServerSession } from "next-auth/next";
import { authOptions } from "@/lib/authOptions";
import { PrismaClient } from "@prisma/client";
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const prisma = new PrismaClient();

// AI í‹°ì–´ íƒ€ì… ì •ì˜
type AITier = {
  model: string;
  name: string;
  description: string;
};

// AI ëª¨ë¸ í‹°ì–´ ì •ì˜
const AI_TIERS: Record<string, AITier> = {
  GUEST: {
    model: 'gpt-3.5-turbo',
    name: 'ê¸°ë³¸ AI',
    description: 'ë¹ ë¥´ê³  ê¸°ë³¸ì ì¸ ì‘ë‹µ'
  },
  USER: {
    model: 'gpt-4o-mini',
    name: 'í–¥ìƒëœ AI', 
    description: 'ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ì‘ë‹µ'
  },
  PREMIUM: {
    model: 'gpt-4o',
    name: 'í”„ë¦¬ë¯¸ì—„ AI',
    description: 'ìµœê³  ìˆ˜ì¤€ì˜ ì •í™•í•˜ê³  ì°½ì˜ì ì¸ ì‘ë‹µ'
  }
};

export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json();

    if (!message) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ì„¸ì…˜ í™•ì¸
    const session = await getServerSession(authOptions);
    
    // ì‚¬ìš©ì í‹°ì–´ ê²°ì •
    let userTier: AITier = AI_TIERS.GUEST;
    let isPremium = false;
    let userId = null;

    if (session?.user?.email) {
      // ë¡œê·¸ì¸í•œ ì‚¬ìš©ì - ê²°ì œ ìƒíƒœ í™•ì¸
      const user = await prisma.user.findUnique({
        where: { email: session.user.email },
        include: {
          payments: {
            where: { status: 'completed' },
            orderBy: { createdAt: 'desc' },
            take: 1
          }
        }
      });

      if (user) {
        userId = user.id;
        // ìµœê·¼ ê²°ì œ ë‚´ì—­ì´ ìˆìœ¼ë©´ í”„ë¦¬ë¯¸ì—„
        isPremium = user.payments.length > 0;
        userTier = isPremium ? AI_TIERS.PREMIUM : AI_TIERS.USER;
      }
    }

    console.log(`AI ì±„íŒ… ìš”ì²­ - í‹°ì–´: ${userTier.name}, ëª¨ë¸: ${userTier.model}`);

    // AI ì‘ë‹µ ìƒì„±
    const completion = await openai.chat.completions.create({
      model: userTier.model as any,
      messages: [
        {
          role: "system",
          content: getUserSystemPrompt(userTier, isPremium)
        },
        {
          role: "user",
          content: message
        }
      ],
      max_tokens: getMaxTokens(userTier),
      temperature: getTemperature(userTier)
    });

    let response = completion.choices[0].message.content || '';
    
    // ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìì—ê²Œ ë¡œê·¸ì¸ ìœ ë„ ë©”ì‹œì§€ ì¶”ê°€
    if (!session) {
      response = addLoginPromptMessage(response);
    }

    return NextResponse.json({
      response,
      tier: {
        name: userTier.name,
        description: userTier.description,
        model: userTier.model
      },
      premium: isPremium,
      authenticated: !!session
    });

  } catch (error) {
    console.error('Chat API Error:', error);
    return NextResponse.json(
      { error: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}

// í‹°ì–´ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
function getUserSystemPrompt(tier: AITier, isPremium: boolean): string {
  const basePrompt = "ë‹¹ì‹ ì€ MOAì˜ AI ê²€ìƒ‰ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.";
  
  if (tier === AI_TIERS.GUEST) {
    return `${basePrompt} ê°„ë‹¨í•˜ê³  ê¸°ë³¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ê°€ëŠ¥í•œ í•œ ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.`;
  } else if (tier === AI_TIERS.USER) {
    return `${basePrompt} ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì ì ˆí•œ ìˆ˜ì¤€ì˜ ìƒì„¸í•¨ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.`;
  } else if (tier === AI_TIERS.PREMIUM) {
    return `${basePrompt} ë§¤ìš° ìƒì„¸í•˜ê³  ì°½ì˜ì ì´ë©° ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë‹¤ì–‘í•œ ê´€ì ê³¼ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.`;
  }
  
  return basePrompt;
}

// í‹°ì–´ë³„ ìµœëŒ€ í† í° ìˆ˜
function getMaxTokens(tier: AITier): number {
  if (tier === AI_TIERS.GUEST) {
    return 150;  // ì§§ì€ ë‹µë³€
  } else if (tier === AI_TIERS.USER) {
    return 500;  // ë³´í†µ ê¸¸ì´
  } else if (tier === AI_TIERS.PREMIUM) {
    return 1500; // ìƒì„¸í•œ ë‹µë³€
  }
  return 300;
}

// í‹°ì–´ë³„ ì°½ì˜ì„± ìˆ˜ì¤€
function getTemperature(tier: AITier): number {
  if (tier === AI_TIERS.GUEST) {
    return 0.3; // ì¼ê´€ì„± ì¤‘ì‹¬
  } else if (tier === AI_TIERS.USER) {
    return 0.7; // ê· í˜•
  } else if (tier === AI_TIERS.PREMIUM) {
    return 0.8; // ì°½ì˜ì„± ì¤‘ì‹¬
  }
  return 0.5;
}

// ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ììš© ë¡œê·¸ì¸ ìœ ë„ ë©”ì‹œì§€ ì¶”ê°€
function addLoginPromptMessage(response: string): string {
  const loginPrompts = [
    "\n\nğŸ’¡ **ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì›í•˜ì‹œë‚˜ìš”?** ë¡œê·¸ì¸í•˜ì‹œë©´ í–¥ìƒëœ GPT-4o-mini ëª¨ë¸ë¡œ ë” ë‚˜ì€ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆì–´ìš”!",
    "\n\nğŸ¯ **ë¡œê·¸ì¸í•˜ë©´ ë” ìŠ¤ë§ˆíŠ¸í•œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆì–´ìš”!** ì§€ê¸ˆë³´ë‹¤ í›¨ì”¬ ì •í™•í•˜ê³  ì°½ì˜ì ì¸ ë‹µë³€ì„ ê²½í—˜í•´ë³´ì„¸ìš”.",
    "\n\nâœ¨ **í”„ë¦¬ë¯¸ì—„ AI ê²½í—˜ì„ ì›í•˜ì‹ ë‹¤ë©´?** ë¡œê·¸ì¸ í›„ ê²°ì œí•˜ì‹œë©´ ìµœê³ ê¸‰ GPT-4o ëª¨ë¸ì„ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!",
    "\n\nğŸš€ **ì´ê±´ ê¸°ë³¸ AIì˜ ë‹µë³€ì´ì—ìš”.** ë¡œê·¸ì¸í•˜ë©´ ë” ë˜‘ë˜‘í•œ AIì™€ ëŒ€í™”í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”!",
    "\n\nğŸ“ˆ **ë” ë‚˜ì€ AI ê²½í—˜ì„ ì›í•˜ì‹œë‚˜ìš”?** ë¡œê·¸ì¸ ì‹œ GPT-4o-mini, ê²°ì œ ì‹œ GPT-4oë¡œ ì—…ê·¸ë ˆì´ë“œë©ë‹ˆë‹¤!",
    "\n\nğŸ¨ **í˜„ì¬ëŠ” ê¸°ë³¸ ë²„ì „ì…ë‹ˆë‹¤.** ë¡œê·¸ì¸í•˜ë©´ ë” ì°½ì˜ì ì´ê³  ì •í™•í•œ AI ë‹µë³€ì„ ë°›ì•„ë³´ì„¸ìš”!"
  ];
  
  const randomPrompt = loginPrompts[Math.floor(Math.random() * loginPrompts.length)];
  return response + randomPrompt;
} 